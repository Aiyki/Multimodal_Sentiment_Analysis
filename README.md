# Multimodal_Sentiment_Analysis
# Мультимодальная классификация эмоций (Текст + Аудио)

Курсовая работа по предмету "Глубокое машинное обучение".
Студент: Абрамова Варвара Максимовна, М4121
Университет ИТМО

## Описание проекта

Данный проект посвящен разработке и исследованию моделей для бинарной классификации эмоциональной окраски (наличие/отсутствие эмоции) на основе текстовых транскрипций и аудиозаписей. В работе рассматриваются унимодальные и мультимодальные подходы.

## Структура репозитория

-   `00_Setup_and_Data_Loading.ipynb`: Ноутбук для установки зависимостей (если необходимо), конфигурации путей и начальной загрузки данных.
-   `01_EDA.ipynb`: Ноутбук с кодом для эксполаторного анализа данных (EDA) и соответствующими выводами.
-   `02_Baseline_Models.ipynb`: Реализация и оценка базовых (baseline) унимодальных моделей (MLPClassifier на TF-IDF, BoW для текста; MLPClassifier на LLD+Stats, Avg MFCC для аудио).
-   `03_Advanced_Models.ipynb`: Реализация и оценка более сложных унимодальных моделей (LinearSVC для текста, RandomForestClassifier для аудио) с подбором гиперпараметров.
-   `04_Fusion_Models.ipynb`: Реализация и оценка стратегий мультимодального слияния (раннее и позднее слияние).
-   `joblib_cache/` (директория, создаваемая скриптом): Используется для кэширования извлеченных аудио признаков и обученных моделей для ускорения повторных запусков. **Эта директория не должна быть включена в репозиторий, если файлы большие.**
-   `data/` (пример): Рекомендуется создать такую директорию и поместить в нее CSV файлы, если они небольшие. Аудиофайлы (папка `Wav_16000`) обычно не загружаются в репозиторий из-за размера.

## Данные

Для работы использовался корпус данных **[УТОЧНИТЬ: Название корпуса, если есть, или "предоставленный учебный корпус"]**, содержащий [количество] записей с текстовыми транскрипциями и аудиодорожками.
-   CSV файлы с метаданными: `Data_Train_modified.csv`, `Data_Val_modified.csv`, `Data_Test_original.csv`.
-   Аудиофайлы: Расположены в директории `Wav_16000` (не включены в данный репозиторий из-за размера). **[УТОЧНИТЬ: Откуда взять аудио, если это публичный датасет, или указать, что они предоставляются отдельно]**.

## Как пользоваться

1.  **Клонировать репозиторий:**
    ```bash
    git clone [URL вашего репозитория]
    cd [название папки репозитория]
    ```

2.  **Настройка окружения и данных:**
    *   Убедитесь, что у вас установлен Python 3.x и Jupyter Notebook/JupyterLab.
    *   Установите необходимые библиотеки. Можно использовать первую ячейку в `00_Setup_and_Data_Loading.ipynb` или выполнить:
        ```bash
        pip install pandas numpy librosa scikit-learn matplotlib seaborn tqdm joblib imbalanced-learn nltk pymystem3 gensim requests optuna
        ```
    *   **Скачайте аудиофайлы** (если они не включены) и поместите их в папку `Wav_16000` внутри основной директории проекта (или обновите путь `AUDIO_DIR` в ноутбуке `00_Setup_and_Data_Loading.ipynb`).
    *   **Поместите CSV файлы** (`Data_Train_modified.csv` и т.д.) в основную директорию проекта (или обновите пути `TRAIN_CSV` и т.д. в ноутбуке `00_Setup_and_Data_Loading.ipynb`). Лучше всего создать подпапку `data/` и сложить их туда, соответственно обновив пути в коде.
    *   **Проверьте и при необходимости исправьте `DATA_DIR`** в ячейке конфигурации ноутбука `00_Setup_and_Data_Loading.ipynb`, чтобы он указывал на корневую папку вашего локального проекта.

3.  **Запуск ноутбуков:**
    *   Откройте Jupyter Notebook или JupyterLab.
    *   Выполняйте ячейки в ноутбуках последовательно, начиная с `00_Setup_and_Data_Loading.ipynb`, затем `01_EDA.ipynb` и так далее.
    *   Длительные операции, такие как извлечение аудио признаков и подбор гиперпараметров, могут кэшировать свои результаты в папку `joblib_cache/` для ускорения последующих запусков (если соответствующие флаги `RUN_..._EXTRACTION` или `RUN_..._TUNING` установлены в `False` после первого успешного выполнения).

## Результаты

Основные результаты экспериментов представлены в соответствующих ноутбуках и сведены в итоговых таблицах. Лучшая модель [укажи какая, например, "позднего слияния"] достигла F1-score (weighted) [твое лучшее значение].

## Зависимости

- Python 3.x
- pandas
- numpy
- librosa
- scikit-learn
- matplotlib
- seaborn
- tqdm
- joblib
- imbalanced-learn
- nltk (с загруженными 'stopwords' и 'punkt')
- pymystem3 (если использовался в EDA для токенизации/лемматизации облаков слов)
- gensim (если использовался)
- requests (если была автоматическая загрузка моделей)
- optuna (если использовался для подбора гиперпараметров)

*(Убери из списка те, что в итоге не использовались в финальной версии кода)*
